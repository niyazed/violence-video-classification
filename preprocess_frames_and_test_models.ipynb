{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Preprocess frames for LSTM\n",
    "\n",
    "Timesteps = 30\n",
    "\n",
    "Each Class 720 frames\n",
    "\n",
    "720/30 = 24 \n",
    "\n",
    "NUMBER OF SAMPLES, TIMESTEPS, WIDTH, HIEGHT, CHANNEL\n",
    "Final Shape: (24, 30, 224, 224, 3)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import sklearn\n",
    "import pandas\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import *\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_path = \"frames/violent/\"\n",
    "nv_path = \"frames/non_violent/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_frames = []\n",
    "non_violent_frames = []\n",
    "\n",
    "for frame in os.listdir(v_path):\n",
    "    frame = cv2.imread(os.path.join(v_path,frame))\n",
    "    violent_frames.append(frame)\n",
    "\n",
    "\n",
    "for frame in os.listdir(nv_path):\n",
    "    frame = cv2.imread(os.path.join(nv_path,frame))\n",
    "    non_violent_frames.append(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates sequence \n",
    "# SHAPE : (N_SAMPLES,TIMESTEP,WIDTH,HEIGHT,CHANNEL)\n",
    "def create_seq(violent_frames, non_violent_frames):\n",
    "    \n",
    "    print(\"+++ Creating Sequence... +++\")\n",
    "    \n",
    "    violent_vid = []\n",
    "    non_violent_vid = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(violent_frames):\n",
    "        violent_vid.append(violent_frames[i:i+30])\n",
    "        i = i+30\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while i < len(non_violent_frames):\n",
    "        non_violent_vid.append(non_violent_frames[i:i+30])\n",
    "        i = i+30\n",
    "        \n",
    "    violent_vid = np.asarray(violent_vid)\n",
    "    non_violent_vid = np.asarray(non_violent_vid)\n",
    "    \n",
    "    return violent_vid, non_violent_vid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(x,y):\n",
    "    \n",
    "    print(\"+++ Generating result... +++\")\n",
    "    \n",
    "    pred = model.predict(x)\n",
    "#     print('First prediction:', pred)\n",
    "    \n",
    "    score = model.evaluate(x, y,verbose=1)\n",
    "    print(\"-----------------------------\")\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    prediction = []\n",
    "    for p in pred:\n",
    "        if p>=.5:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Classification report\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(classification_report(y, prediction))\n",
    "    \n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"-----------------------------\")\n",
    "    conf_mat = confusion_matrix(y, prediction)\n",
    "    print(conf_mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lstm(features):\n",
    "    \n",
    "    print(\"+++ Preprocessing data... +++\")\n",
    "    \n",
    "    violent_features = features[0:240]\n",
    "    non_violent_features = features[240:]\n",
    "\n",
    "    print(\"Violent features: \", violent_features.shape)\n",
    "    print(\"Non Violent features: \", non_violent_features.shape)\n",
    "\n",
    "\n",
    "    violent_vid,non_violent_vid = create_seq(violent_features, non_violent_features)\n",
    "    violent_y, non_violent_y = np.zeros(len(violent_vid)), np.ones(len(non_violent_vid))\n",
    "\n",
    "    print(\"Violent Video Seq: \", violent_vid.shape,\"Non_violent video Seq: \", non_violent_vid.shape)\n",
    "    print(\"Violent Label: \", violent_y.shape, \"Non_violent Label: \", non_violent_y.shape)\n",
    "\n",
    "\n",
    "    test_x = np.vstack((violent_vid,non_violent_vid))\n",
    "    test_y = np.append(violent_y, non_violent_y)\n",
    "\n",
    "    print(\"Total data: \", test_x.shape)\n",
    "    print(\"Total target: \", test_y.shape)\n",
    "\n",
    "    test_x = np.reshape(test_x, (test_x.shape[0],test_x.shape[1],np.prod(test_x.shape[2:])))\n",
    "    print(\"(LSTM) After Rehshape: \", test_x.shape)\n",
    "    \n",
    "    return test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(violent_frames, non_violent_frames, model):\n",
    "    \n",
    "    print(\"+++ Extracting feature... +++\")\n",
    "    \n",
    "    violent_frames = np.asarray(violent_frames)\n",
    "    non_violent_frames = np.asarray(non_violent_frames)\n",
    "\n",
    "    print (\"Before Feature extraction: \")\n",
    "    print(violent_frames.shape,non_violent_frames.shape)\n",
    "    all_data = np.vstack((violent_frames,non_violent_frames))\n",
    "    print(\"Adding all data: \", all_data.shape)\n",
    "\n",
    "    #creates feature descriptors\n",
    "    desc = preprocess_input(all_data)\n",
    "    if(model == 'resnet50'):\n",
    "        loaded_model = resnet50.ResNet50(input_shape=(224,224,3), include_top=False)\n",
    "    elif(model == 'vgg19'):\n",
    "        loaded_model = VGG19(input_shape=(224,224,3), include_top=False)\n",
    "    elif(model == 'vgg16'):\n",
    "        loaded_model = VGG16(input_shape=(224,224,3), include_top=False)\n",
    "    else:\n",
    "        print(\"Please give model name - 'resnet50', 'vgg19', 'vgg16'\")\n",
    "        \n",
    "    loaded_model = Model(loaded_model.input,loaded_model.output)\n",
    "    features = loaded_model.predict(desc,batch_size=10,verbose=1)\n",
    "\n",
    "    print (\"After Feature extraction: \", features.shape)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting feature... +++\n",
      "Before Feature extraction: \n",
      "(240, 224, 224, 3) (240, 224, 224, 3)\n",
      "Adding all data:  (480, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 5s 11ms/step\n",
      "After Feature extraction:  (480, 7, 7, 2048)\n",
      "+++ Preprocessing data... +++\n",
      "Violent features:  (240, 7, 7, 2048)\n",
      "Non Violent features:  (240, 7, 7, 2048)\n",
      "+++ Creating Sequence... +++\n",
      "Violent Video Seq:  (8, 30, 7, 7, 2048) Non_violent video Seq:  (8, 30, 7, 7, 2048)\n",
      "Violent Label:  (8,) Non_violent Label:  (8,)\n",
      "Total data:  (16, 30, 7, 7, 2048)\n",
      "Total target:  (16,)\n",
      "(LSTM) After Rehshape:  (16, 30, 100352)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 50)                20080800  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 20,080,851\n",
      "Trainable params: 20,080,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "+++ Generating result... +++\n",
      "16/16 [==============================] - 0s 21ms/step\n",
      "-----------------------------\n",
      "Test loss: 0.5757079124450684\n",
      "Test accuracy: 0.9375\n",
      "-----------------------------\n",
      "Classification report\n",
      "-----------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.88      0.93         8\n",
      "        1.0       0.89      1.00      0.94         8\n",
      "\n",
      "avg / total       0.94      0.94      0.94        16\n",
      "\n",
      "-----------------------------\n",
      "Confusion Matrix\n",
      "-----------------------------\n",
      "[[7 1]\n",
      " [0 8]]\n"
     ]
    }
   ],
   "source": [
    "features = feature_extract(violent_frames, non_violent_frames, 'resnet50')\n",
    "test_x, test_y = preprocess_lstm(features)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(50, input_shape=(test_x.shape[1],test_x.shape[2]), return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.load_weights('resnet_LSTM.h5')\n",
    "model.summary()\n",
    "optimizer = optimizers.adam(lr=0.001,decay=0.004)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "result(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting feature... +++\n",
      "Before Feature extraction: \n",
      "(240, 224, 224, 3) (240, 224, 224, 3)\n",
      "Adding all data:  (480, 224, 224, 3)\n",
      "480/480 [==============================] - 5s 11ms/step\n",
      "After Feature extraction:  (480, 7, 7, 512)\n",
      "+++ Preprocessing data... +++\n",
      "Violent features:  (240, 7, 7, 512)\n",
      "Non Violent features:  (240, 7, 7, 512)\n",
      "+++ Creating Sequence... +++\n",
      "Violent Video Seq:  (8, 30, 7, 7, 512) Non_violent video Seq:  (8, 30, 7, 7, 512)\n",
      "Violent Label:  (8,) Non_violent Label:  (8,)\n",
      "Total data:  (16, 30, 7, 7, 512)\n",
      "Total target:  (16,)\n",
      "(LSTM) After Rehshape:  (16, 30, 25088)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 50)                5028000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,028,051\n",
      "Trainable params: 5,028,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "+++ Generating result... +++\n",
      "16/16 [==============================] - 0s 14ms/step\n",
      "-----------------------------\n",
      "Test loss: 0.6941779851913452\n",
      "Test accuracy: 0.8125\n",
      "-----------------------------\n",
      "Classification report\n",
      "-----------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.62      0.77         8\n",
      "        1.0       0.73      1.00      0.84         8\n",
      "\n",
      "avg / total       0.86      0.81      0.81        16\n",
      "\n",
      "-----------------------------\n",
      "Confusion Matrix\n",
      "-----------------------------\n",
      "[[5 3]\n",
      " [0 8]]\n"
     ]
    }
   ],
   "source": [
    "features = feature_extract(violent_frames, non_violent_frames, 'vgg19')\n",
    "test_x, test_y = preprocess_lstm(features)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(50, input_shape=(test_x.shape[1],test_x.shape[2]), return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.load_weights('vgg19_LSTM.h5')\n",
    "model.summary()\n",
    "optimizer = optimizers.adam(lr=0.001,decay=0.004)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "result(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting feature... +++\n",
      "Before Feature extraction: \n",
      "(240, 224, 224, 3) (240, 224, 224, 3)\n",
      "Adding all data:  (480, 224, 224, 3)\n",
      "480/480 [==============================] - 9s 20ms/step\n",
      "After Feature extraction:  (480, 7, 7, 512)\n",
      "+++ Preprocessing data... +++\n",
      "Violent features:  (240, 7, 7, 512)\n",
      "Non Violent features:  (240, 7, 7, 512)\n",
      "+++ Creating Sequence... +++\n",
      "Violent Video Seq:  (8, 30, 7, 7, 512) Non_violent video Seq:  (8, 30, 7, 7, 512)\n",
      "Violent Label:  (8,) Non_violent Label:  (8,)\n",
      "Total data:  (16, 30, 7, 7, 512)\n",
      "Total target:  (16,)\n",
      "(LSTM) After Rehshape:  (16, 30, 25088)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 200 and 400. Shapes are [25088,200] and [25088,400]. for 'Assign_6572' (op: 'Assign') with input shapes: [25088,200], [25088,400].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1575\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 200 and 400. Shapes are [25088,200] and [25088,400]. for 'Assign_6572' (op: 'Assign') with input shapes: [25088,200], [25088,400].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-40e0fc4ed518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vgg16_LSTM.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.004\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                              ' elements.')\n\u001b[0;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2463\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2464\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2465\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2466\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    643\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \"\"\"\n\u001b[1;32m--> 645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    214\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    215\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    217\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     61\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m     62\u001b[0m         \u001b[1;34m\"Assign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3155\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1731\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 200 and 400. Shapes are [25088,200] and [25088,400]. for 'Assign_6572' (op: 'Assign') with input shapes: [25088,200], [25088,400]."
     ]
    }
   ],
   "source": [
    "features = feature_extract(violent_frames, non_violent_frames, 'vgg16')\n",
    "test_x, test_y = preprocess_lstm(features)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(50, input_shape=(test_x.shape[1],test_x.shape[2]), return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.load_weights('vgg16_LSTM.h5')\n",
    "model.summary()\n",
    "optimizer = optimizers.adam(lr=0.001,decay=0.004)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "result(test_x,test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_initial_weights\n",
    "from layers import BilinearInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x, model_weights):\n",
    "    \n",
    "    num_classes=1\n",
    "    image = Input(shape=(x.shape[1], x.shape[2], x.shape[3]))\n",
    "\n",
    "    locnet = Conv2D(2, (1, 1),kernel_regularizer=regularizers.l2(0.01))(image)\n",
    "    locnet = Conv2D(2, (1, 1),kernel_regularizer=regularizers.l2(0.01))(locnet)\n",
    "    locnet = Flatten()(locnet)\n",
    "    locnet = Dense(5,kernel_regularizer=regularizers.l2(0.01))(locnet)\n",
    "    locnet = Activation('relu')(locnet)\n",
    "\n",
    "    weights = get_initial_weights(5)\n",
    "\n",
    "    locnet = Dense(6, weights=weights,kernel_regularizer=regularizers.l2(0.01))(locnet)\n",
    "\n",
    "    x = BilinearInterpolation((3,3))([image, locnet])\n",
    "\n",
    "    x = Conv2D(2, (1, 1), padding='same',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(2, (1, 1),kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64,kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(num_classes)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    model = Model(inputs=image, outputs=x)\n",
    "\n",
    "    model.summary()\n",
    "    adam = optimizers.Adam(lr=.001)\n",
    "    model.load_weights(model_weights)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting feature... +++\n",
      "Before Feature extraction: \n",
      "(240, 224, 224, 3) (240, 224, 224, 3)\n",
      "Adding all data:  (480, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 4s 8ms/step\n",
      "After Feature extraction:  (480, 7, 7, 2048)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 7, 7, 2048)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 2)      4098        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 2)      6           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 98)           0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            495         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 5)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            36          activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_interpolation_1 (Bilin (None, 3, 3, 2048)   0           input_4[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 2)      4098        bilinear_interpolation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 3, 3, 2)      0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 2)      6           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 3, 3, 2)      0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 18)           0           activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           1216        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            65          activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 1)            0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,020\n",
      "Trainable params: 10,020\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "+++ Generating result... +++\n",
      "480/480 [==============================] - 1s 1ms/step\n",
      "-----------------------------\n",
      "Test loss: 0.3076687862475713\n",
      "Test accuracy: 0.9020833333333333\n",
      "-----------------------------\n",
      "Classification report\n",
      "-----------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.83      0.89       240\n",
      "        1.0       0.85      0.97      0.91       240\n",
      "\n",
      "avg / total       0.91      0.90      0.90       480\n",
      "\n",
      "-----------------------------\n",
      "Confusion Matrix\n",
      "-----------------------------\n",
      "[[199  41]\n",
      " [  6 234]]\n"
     ]
    }
   ],
   "source": [
    "features = feature_extract(violent_frames, non_violent_frames, 'resnet50')\n",
    "violent_y, non_violent_y = np.zeros(240), np.ones(240)\n",
    "\n",
    "test_x = features\n",
    "test_y = np.append(violent_y, non_violent_y)\n",
    "\n",
    "model = build_model(test_x,'resnet_att.h5')\n",
    "\n",
    "result(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting feature... +++\n",
      "Before Feature extraction: \n",
      "(240, 224, 224, 3) (240, 224, 224, 3)\n",
      "Adding all data:  (480, 224, 224, 3)\n",
      "480/480 [==============================] - 5s 10ms/step\n",
      "After Feature extraction:  (480, 7, 7, 512)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 7, 7, 512)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 2)      1026        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 2)      6           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 98)           0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 5)            495         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 5)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 6)            36          activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_interpolation_2 (Bilin (None, 3, 3, 512)    0           input_6[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 2)      1026        bilinear_interpolation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 3, 3, 2)      0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 2)      6           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 3, 3, 2)      0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 18)           0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           1216        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            65          activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 1)            0           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,876\n",
      "Trainable params: 3,876\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "+++ Generating result... +++\n",
      "480/480 [==============================] - 1s 1ms/step\n",
      "-----------------------------\n",
      "Test loss: 0.7448623130718867\n",
      "Test accuracy: 0.8166666666666667\n",
      "-----------------------------\n",
      "Classification report\n",
      "-----------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.75      0.80       240\n",
      "        1.0       0.78      0.88      0.83       240\n",
      "\n",
      "avg / total       0.82      0.82      0.82       480\n",
      "\n",
      "-----------------------------\n",
      "Confusion Matrix\n",
      "-----------------------------\n",
      "[[180  60]\n",
      " [ 28 212]]\n"
     ]
    }
   ],
   "source": [
    "features = feature_extract(violent_frames, non_violent_frames, 'vgg19')\n",
    "violent_y, non_violent_y = np.zeros(240), np.ones(240)\n",
    "\n",
    "test_x = features\n",
    "test_y = np.append(violent_y, non_violent_y)\n",
    "\n",
    "model = build_model(test_x,'vgg19_att.h5')\n",
    "\n",
    "result(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting feature... +++\n",
      "Before Feature extraction: \n",
      "(240, 224, 224, 3) (240, 224, 224, 3)\n",
      "Adding all data:  (480, 224, 224, 3)\n",
      "480/480 [==============================] - 10s 20ms/step\n",
      "After Feature extraction:  (480, 7, 7, 512)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           (None, 7, 7, 512)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 2)      1026        input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 2)      6           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 98)           0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 5)            495         flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1041 (Activation)    (None, 5)            0           dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 6)            36          activation_1041[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_interpolation_13 (Bili (None, 3, 3, 512)    0           input_47[0][0]                   \n",
      "                                                                 dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 3, 3, 2)      1026        bilinear_interpolation_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1042 (Activation)    (None, 3, 3, 2)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 3, 3, 2)      6           activation_1042[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1043 (Activation)    (None, 3, 3, 2)      0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 18)           0           activation_1043[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 64)           1216        flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1044 (Activation)    (None, 64)           0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1)            65          activation_1044[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1045 (Activation)    (None, 1)            0           dense_69[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,876\n",
      "Trainable params: 3,876\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 1 and 2. Shapes are [1,1,512,2] and [2,2048,1,1]. for 'Assign_6977' (op: 'Assign') with input shapes: [1,1,512,2], [2,2048,1,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1575\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 2. Shapes are [1,1,512,2] and [2,2048,1,1]. for 'Assign_6977' (op: 'Assign') with input shapes: [1,1,512,2], [2,2048,1,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-109f56e46b34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviolent_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_violent_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'vgg16_att.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-6f585fb0eb90>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(x, model_weights)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                              ' elements.')\n\u001b[0;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2463\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2464\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2465\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2466\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    643\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \"\"\"\n\u001b[1;32m--> 645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    214\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    215\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    217\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     61\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m     62\u001b[0m         \u001b[1;34m\"Assign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3155\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1731\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 2. Shapes are [1,1,512,2] and [2,2048,1,1]. for 'Assign_6977' (op: 'Assign') with input shapes: [1,1,512,2], [2,2048,1,1]."
     ]
    }
   ],
   "source": [
    "features = feature_extract(violent_frames, non_violent_frames, 'vgg16')\n",
    "violent_y, non_violent_y = np.zeros(240), np.ones(240)\n",
    "\n",
    "test_x = features\n",
    "test_y = np.append(violent_y, non_violent_y)\n",
    "\n",
    "model = build_model(test_x,'vgg16_att.h5')\n",
    "\n",
    "result(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
